{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dzie≈Ñ 2 - Modu≈Ç 5: Generowanie i rozumienie tekstu\n",
    "\n",
    "## Cele modu≈Çu:\n",
    "- Tworzenie podsumowa≈Ñ tekstu (summarization)\n",
    "- Generowanie tre≈õci (text generation)\n",
    "- Automatyczne t≈Çumaczenia\n",
    "- Analiza sentymentu w praktyce\n",
    "- Question Answering (systemy Q&A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import bibliotek\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"‚úÖ Biblioteki za≈Çadowane!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Podsumowania tekstu (Text Summarization)\n",
    "\n",
    "### Rodzaje podsumowa≈Ñ:\n",
    "\n",
    "#### 1. Extractive Summarization\n",
    "- Wybiera najwa≈ºniejsze zdania z oryginalnego tekstu\n",
    "- Nie tworzy nowych zda≈Ñ\n",
    "- Szybsze, prostsze\n",
    "- Przyk≈Çad: wyb√≥r 3 najwa≈ºniejszych zda≈Ñ z artyku≈Çu\n",
    "\n",
    "#### 2. Abstractive Summarization\n",
    "- Generuje nowe zdania\n",
    "- Parafrazy i przepisywanie\n",
    "- Bardziej \"ludzkie\" podsumowania\n",
    "- Wymaga modeli Seq2Seq (np. T5, BART, Pegasus)\n",
    "\n",
    "### Zastosowania:\n",
    "- Streszczenia artyku≈Ç√≥w\n",
    "- Agregacja wiadomo≈õci\n",
    "- Podsumowania spotka≈Ñ\n",
    "- Analiza dokument√≥w prawnych\n",
    "- Podsumowania recenzji produkt√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 1: Abstractive Summarization\n",
    "print(\"=== ABSTRACTIVE SUMMARIZATION ===\")\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "article = \"\"\"\n",
    "Artificial intelligence has made tremendous progress in recent years, particularly \n",
    "in the field of natural language processing. Large language models like GPT-3 and \n",
    "GPT-4 have demonstrated remarkable capabilities in understanding and generating \n",
    "human-like text. These models are trained on vast amounts of text data and can \n",
    "perform a wide variety of tasks without specific training for each task. The impact \n",
    "of these advances extends across multiple industries including healthcare, finance, \n",
    "education, and customer service. However, there are also important concerns about \n",
    "bias, misinformation, and the ethical implications of AI systems. As these \n",
    "technologies continue to evolve, it's crucial to develop appropriate guidelines \n",
    "and regulations to ensure they benefit society as a whole.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ARTYKU≈Å ORYGINALNY:\")\n",
    "print(article.strip())\n",
    "print(f\"\\nLiczba s≈Ç√≥w: {len(article.split())}\")\n",
    "\n",
    "# Podsumowanie\n",
    "summary = summarizer(\n",
    "    article, \n",
    "    max_length=60, \n",
    "    min_length=30, \n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PODSUMOWANIE:\")\n",
    "print(summary[0]['summary_text'])\n",
    "print(f\"\\nLiczba s≈Ç√≥w: {len(summary[0]['summary_text'].split())}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 2: R√≥≈ºne d≈Çugo≈õci podsumowa≈Ñ\n",
    "print(\"\\n=== PODSUMOWANIA O R√ì≈ªNEJ D≈ÅUGO≈öCI ===\")\n",
    "\n",
    "lengths = [\n",
    "    {\"max\": 30, \"min\": 20, \"name\": \"Kr√≥tkie\"},\n",
    "    {\"max\": 60, \"min\": 40, \"name\": \"≈örednie\"},\n",
    "    {\"max\": 100, \"min\": 70, \"name\": \"D≈Çugie\"},\n",
    "]\n",
    "\n",
    "for config in lengths:\n",
    "    summary = summarizer(\n",
    "        article,\n",
    "        max_length=config[\"max\"],\n",
    "        min_length=config[\"min\"],\n",
    "        do_sample=False\n",
    "    )\n",
    "    print(f\"\\n{config['name']} ({config['min']}-{config['max']} s≈Ç√≥w):\")\n",
    "    print(summary[0]['summary_text'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 3: Podsumowanie wielu dokument√≥w\n",
    "print(\"\\n=== PODSUMOWANIE WIELU ARTYKU≈Å√ìW ===\")\n",
    "\n",
    "articles = [\n",
    "    {\n",
    "        \"title\": \"Climate Change Report\",\n",
    "        \"text\": \"Scientists warn that global temperatures are rising at an alarming rate. \"\n",
    "                \"The effects include melting ice caps, rising sea levels, and more frequent \"\n",
    "                \"extreme weather events. Immediate action is needed to reduce carbon emissions.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Tech Industry Growth\",\n",
    "        \"text\": \"The technology sector continues to expand rapidly. Cloud computing, artificial \"\n",
    "                \"intelligence, and cybersecurity are driving innovation. Companies are investing \"\n",
    "                \"heavily in research and development to stay competitive.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Healthcare Innovation\",\n",
    "        \"text\": \"Medical technology is transforming patient care. Telemedicine, AI-assisted \"\n",
    "                \"diagnostics, and personalized treatments are becoming more common. These advances \"\n",
    "                \"promise to improve outcomes and reduce costs.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for article_data in articles:\n",
    "    summary = summarizer(\n",
    "        article_data[\"text\"],\n",
    "        max_length=40,\n",
    "        min_length=20,\n",
    "        do_sample=False\n",
    "    )\n",
    "    print(f\"\\nüì∞ {article_data['title']}\")\n",
    "    print(f\"Orygina≈Ç: {article_data['text'][:100]}...\")\n",
    "    print(f\"Podsumowanie: {summary[0]['summary_text']}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Generowanie tre≈õci (Text Generation)\n",
    "\n",
    "### Zastosowania:\n",
    "- Pisanie artyku≈Ç√≥w i blog√≥w\n",
    "- Generowanie opis√≥w produkt√≥w\n",
    "- Tworzenie tre≈õci marketingowych\n",
    "- Automatyczne odpowiedzi\n",
    "- Kreatywne pisanie (opowiadania, poezja)\n",
    "\n",
    "### Parametry kontroli generowania:\n",
    "- **temperature**: Kontrola \"kreatywno≈õci\" (0 = deterministyczne, 2+ = bardzo kreatywne)\n",
    "- **top_k**: Wyb√≥r spo≈õr√≥d k najbardziej prawdopodobnych s≈Ç√≥w\n",
    "- **top_p**: Nucleus sampling - wyb√≥r spo≈õr√≥d najmniejszego zestawu s≈Ç√≥w o ≈ÇƒÖcznym prawdopodobie≈Ñstwie p\n",
    "- **max_length**: Maksymalna d≈Çugo≈õƒá wygenerowanego tekstu\n",
    "- **num_beams**: Beam search - przeszukiwanie wielu wariant√≥w jednocze≈õnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 1: Podstawowe generowanie tekstu\n",
    "print(\"=== GENEROWANIE TEKSTU ===\")\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "prompt = \"The future of artificial intelligence is\"\n",
    "\n",
    "print(f\"Prompt: {prompt}\\n\")\n",
    "\n",
    "# Generuj kilka wersji\n",
    "results = generator(\n",
    "    prompt,\n",
    "    max_length=80,\n",
    "    num_return_sequences=3,\n",
    "    temperature=0.8,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\nWersja {i}:\")\n",
    "    print(result['generated_text'])\n",
    "    print(\"-\" * 70)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 2: Wp≈Çyw temperature na generowanie\n",
    "print(\"\\n=== WP≈ÅYW TEMPERATURE ===\")\n",
    "\n",
    "temperatures = [0.3, 0.7, 1.2]\n",
    "prompt = \"Machine learning is\"\n",
    "\n",
    "for temp in temperatures:\n",
    "    result = generator(\n",
    "        prompt,\n",
    "        max_length=50,\n",
    "        temperature=temp,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    print(f\"\\nTemperature = {temp}:\")\n",
    "    print(result[0]['generated_text'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 3: Generowanie r√≥≈ºnych typ√≥w tre≈õci\n",
    "print(\"\\n=== GENEROWANIE R√ì≈ªNYCH TYP√ìW TRE≈öCI ===\")\n",
    "\n",
    "prompts = [\n",
    "    \"Write a product description for a smartwatch:\\n\",\n",
    "    \"Create a blog post introduction about healthy eating:\\n\",\n",
    "    \"Write an email subject line for a sale:\\n\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    result = generator(\n",
    "        prompt,\n",
    "        max_length=70,\n",
    "        temperature=0.7,\n",
    "        do_sample=True\n",
    "    )\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(result[0]['generated_text'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Automatyczne t≈Çumaczenia\n",
    "\n",
    "### Rozw√≥j t≈Çumacze≈Ñ maszynowych:\n",
    "1. **Rule-based** (lata 50-80) - regu≈Çy gramatyczne\n",
    "2. **Statistical MT** (lata 90-2010) - statystyki z korpus√≥w r√≥wnoleg≈Çych\n",
    "3. **Neural MT** (2014+) - sieci neuronowe Seq2Seq\n",
    "4. **Transformer-based** (2017+) - modele attention-based\n",
    "\n",
    "### Najpopularniejsze modele:\n",
    "- **MarianMT** - szybkie, lekkie modele dla wielu par jƒôzykowych\n",
    "- **mBART** - wielojƒôzyczny BART\n",
    "- **M2M-100** - bezpo≈õrednie t≈Çumaczenia miƒôdzy 100 jƒôzykami\n",
    "- **NLLB** (No Language Left Behind) - 200+ jƒôzyk√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 1: T≈Çumaczenie angielski ‚Üí niemiecki\n",
    "print(\"=== T≈ÅUMACZENIE: EN ‚Üí DE ===\")\n",
    "\n",
    "translator = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")\n",
    "\n",
    "english_texts = [\n",
    "    \"Hello, how are you today?\",\n",
    "    \"Artificial intelligence is transforming the world.\",\n",
    "    \"I would like to book a table for two people.\",\n",
    "]\n",
    "\n",
    "for text in english_texts:\n",
    "    translation = translator(text)\n",
    "    print(f\"\\nEN: {text}\")\n",
    "    print(f\"DE: {translation[0]['translation_text']}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 2: T≈Çumaczenie angielski ‚Üí francuski\n",
    "print(\"\\n=== T≈ÅUMACZENIE: EN ‚Üí FR ===\")\n",
    "\n",
    "translator_fr = pipeline(\"translation_en_to_fr\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "\n",
    "for text in english_texts:\n",
    "    translation = translator_fr(text)\n",
    "    print(f\"\\nEN: {text}\")\n",
    "    print(f\"FR: {translation[0]['translation_text']}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 3: Wielojƒôzyczne t≈Çumaczenia\n",
    "print(\"\\n=== T≈ÅUMACZENIA WIELOJƒòZYCZNE ===\")\n",
    "\n",
    "# Dla polskiego mo≈ºna u≈ºyƒá dedykowanych modeli\n",
    "# np. Helsinki-NLP/opus-mt-en-pl\n",
    "\n",
    "try:\n",
    "    translator_pl = pipeline(\"translation_en_to_pl\", model=\"Helsinki-NLP/opus-mt-en-pl\")\n",
    "    \n",
    "    text = \"Machine learning is a fascinating field of study.\"\n",
    "    translation = translator_pl(text)\n",
    "    \n",
    "    print(f\"\\nEN: {text}\")\n",
    "    print(f\"PL: {translation[0]['translation_text']}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Model dla polskiego niedostƒôpny: {e}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Analiza sentymentu w praktyce\n",
    "\n",
    "### Poziomy analizy sentymentu:\n",
    "\n",
    "#### 1. Document-level\n",
    "- Sentyment ca≈Çego dokumentu\n",
    "- Przyk≈Çad: recenzja jest pozytywna/negatywna\n",
    "\n",
    "#### 2. Sentence-level\n",
    "- Sentyment ka≈ºdego zdania\n",
    "- Pozwala wykryƒá mieszane opinie\n",
    "\n",
    "#### 3. Aspect-based (ABSA)\n",
    "- Sentyment dla konkretnych aspekt√≥w\n",
    "- Przyk≈Çad: \"Jedzenie ≈õwietne, ale obs≈Çuga s≈Çaba\"\n",
    "  - Jedzenie: pozytywny\n",
    "  - Obs≈Çuga: negatywny\n",
    "\n",
    "### Zastosowania biznesowe:\n",
    "- Monitoring opinii o marce\n",
    "- Analiza recenzji produkt√≥w\n",
    "- Ocena satysfakcji klient√≥w\n",
    "- Analiza nastroj√≥w na rynku finansowym\n",
    "- Moderacja tre≈õci w social media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 1: Podstawowa analiza sentymentu\n",
    "print(\"=== ANALIZA SENTYMENTU ===\")\n",
    "\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "reviews = [\n",
    "    \"This product is absolutely amazing! Best purchase ever!\",\n",
    "    \"Terrible quality. Complete waste of money.\",\n",
    "    \"It's okay, nothing special but does the job.\",\n",
    "    \"Love it! Highly recommend to everyone!\",\n",
    "    \"Disappointed. Not what I expected at all.\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "for review in reviews:\n",
    "    sentiment = sentiment_analyzer(review)[0]\n",
    "    results.append({\n",
    "        'review': review,\n",
    "        'sentiment': sentiment['label'],\n",
    "        'score': sentiment['score']\n",
    "    })\n",
    "    print(f\"\\nRecenzja: {review}\")\n",
    "    print(f\"  ‚Üí {sentiment['label']}: {sentiment['score']:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Wizualizacja wynik√≥w\n",
    "df_sentiment = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Wykres s≈Çupkowy\n",
    "colors = ['green' if s == 'POSITIVE' else 'red' for s in df_sentiment['sentiment']]\n",
    "plt.barh(range(len(df_sentiment)), df_sentiment['score'], color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(df_sentiment)), [r[:40] + '...' if len(r) > 40 else r for r in df_sentiment['review']])\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.title('Analiza Sentymentu Recenzji')\n",
    "plt.axvline(x=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 2: Analiza sentymentu na poziomie zda≈Ñ\n",
    "print(\"\\n=== ANALIZA SENTYMENTU: POZIOM ZDA≈É ===\")\n",
    "\n",
    "text = \"\"\"The hotel room was spacious and clean. The staff was very friendly. \n",
    "However, the breakfast was disappointing. The location is perfect though. \n",
    "Overall, I would recommend this place.\"\"\"\n",
    "\n",
    "# Podziel na zdania\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "print(f\"Tekst oryginalny:\\n{text}\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Analiza zdanie po zdaniu:\\n\")\n",
    "\n",
    "for i, sentence in enumerate(sentences, 1):\n",
    "    sentiment = sentiment_analyzer(sentence)[0]\n",
    "    emoji = \"üòä\" if sentiment['label'] == 'POSITIVE' else \"üòû\"\n",
    "    print(f\"{i}. {sentence}\")\n",
    "    print(f\"   {emoji} {sentiment['label']} ({sentiment['score']:.2f})\\n\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Question Answering (Systemy Q&A)\n",
    "\n",
    "### Rodzaje system√≥w Q&A:\n",
    "\n",
    "#### 1. Extractive QA\n",
    "- Odpowied≈∫ jest fragmentem z podanego tekstu\n",
    "- Model znajduje najbardziej odpowiedni fragment\n",
    "- Przyk≈Çad: SQuAD dataset\n",
    "\n",
    "#### 2. Open-domain QA\n",
    "- Odpowied≈∫ z du≈ºej bazy wiedzy\n",
    "- Wymaga retrieval + reading comprehension\n",
    "\n",
    "#### 3. Generative QA\n",
    "- Model generuje odpowied≈∫\n",
    "- Mo≈ºe tworzyƒá odpowiedzi spoza kontekstu\n",
    "\n",
    "### Zastosowania:\n",
    "- Chatboty i wirtualni asystenci\n",
    "- Wyszukiwarki dokument√≥w\n",
    "- Systemy pomocy technicznej\n",
    "- Platformy edukacyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad: Extractive Question Answering\n",
    "print(\"=== QUESTION ANSWERING ===\")\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "context = \"\"\"\n",
    "Natural Language Processing (NLP) is a field of artificial intelligence that focuses \n",
    "on the interaction between computers and human language. It combines computational \n",
    "linguistics with statistical, machine learning, and deep learning models. Modern NLP \n",
    "has been revolutionized by transformer architectures like BERT and GPT. These models \n",
    "are pre-trained on massive text corpora and can be fine-tuned for specific tasks. \n",
    "Common applications include machine translation, sentiment analysis, text summarization, \n",
    "and question answering systems. The field continues to evolve rapidly with new \n",
    "breakthroughs announced regularly.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"What is NLP?\",\n",
    "    \"What are transformer architectures mentioned?\",\n",
    "    \"What are common applications of NLP?\",\n",
    "    \"How are modern NLP models trained?\",\n",
    "]\n",
    "\n",
    "print(\"KONTEKST:\")\n",
    "print(context.strip())\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    print(f\"‚ùì Pytanie: {question}\")\n",
    "    print(f\"‚úÖ Odpowied≈∫: {result['answer']}\")\n",
    "    print(f\"   (Pewno≈õƒá: {result['score']:.4f})\\n\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Przyk≈Çad 2: Q&A z r√≥≈ºnymi kontekstami\n",
    "print(\"\\n=== Q&A: R√ì≈ªNE DOKUMENTY ===\")\n",
    "\n",
    "documents = [\n",
    "    {\n",
    "        \"title\": \"Company Info\",\n",
    "        \"text\": \"TechCorp was founded in 2010 by Jane Smith and John Doe. \"\n",
    "                \"The company specializes in AI solutions and has offices in \"\n",
    "                \"New York, London, and Tokyo. It currently employs 500 people.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Product Description\",\n",
    "        \"text\": \"Our flagship product, AI Assistant Pro, uses advanced NLP \"\n",
    "                \"to help businesses automate customer support. It supports \"\n",
    "                \"20 languages and can handle 10,000 queries per second.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "questions_per_doc = [\n",
    "    \"Who founded the company?\",\n",
    "    \"How many languages does AI Assistant Pro support?\",\n",
    "]\n",
    "\n",
    "for doc, question in zip(documents, questions_per_doc):\n",
    "    print(f\"\\nüìÑ Dokument: {doc['title']}\")\n",
    "    print(f\"‚ùì Pytanie: {question}\")\n",
    "    \n",
    "    result = qa_pipeline(question=question, context=doc['text'])\n",
    "    print(f\"‚úÖ Odpowied≈∫: {result['answer']}\")\n",
    "    print(f\"   (Pewno≈õƒá: {result['score']:.4f})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒÜwiczenie praktyczne: Kompletny pipeline NLU/NLG\n",
    "\n",
    "### Zadanie:\n",
    "Stw√≥rz system, kt√≥ry:\n",
    "1. Przyjmuje d≈Çugi artyku≈Ç\n",
    "2. Tworzy jego podsumowanie\n",
    "3. Analizuje sentyment\n",
    "4. Odpowiada na pytania o artyku≈Ç\n",
    "5. Generuje tytu≈Ç dla artyku≈Çu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Kompletny pipeline NLP\n",
    "class NLPPipeline:\n",
    "    def __init__(self):\n",
    "        print(\"≈Åadowanie modeli...\")\n",
    "        self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "        self.sentiment = pipeline(\"sentiment-analysis\")\n",
    "        self.qa = pipeline(\"question-answering\")\n",
    "        self.generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "        print(\"‚úÖ Pipeline gotowy!\\n\")\n",
    "    \n",
    "    def analyze_article(self, article, questions=None):\n",
    "        print(\"=\"*70)\n",
    "        print(\"ANALIZA ARTYKU≈ÅU\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # 1. Podsumowanie\n",
    "        print(\"\\n1Ô∏è‚É£ PODSUMOWANIE:\")\n",
    "        summary = self.summarizer(article, max_length=60, min_length=30)\n",
    "        summary_text = summary[0]['summary_text']\n",
    "        print(summary_text)\n",
    "        \n",
    "        # 2. Analiza sentymentu\n",
    "        print(\"\\n2Ô∏è‚É£ SENTYMENT:\")\n",
    "        sentiment = self.sentiment(summary_text)[0]\n",
    "        emoji = \"üòä\" if sentiment['label'] == 'POSITIVE' else \"üòû\"\n",
    "        print(f\"{emoji} {sentiment['label']} (pewno≈õƒá: {sentiment['score']:.2%})\")\n",
    "        \n",
    "        # 3. Question Answering\n",
    "        if questions:\n",
    "            print(\"\\n3Ô∏è‚É£ ODPOWIEDZI NA PYTANIA:\")\n",
    "            for q in questions:\n",
    "                answer = self.qa(question=q, context=article)\n",
    "                print(f\"\\n‚ùì {q}\")\n",
    "                print(f\"‚úÖ {answer['answer']}\")\n",
    "        \n",
    "        # 4. Generowanie tytu≈Çu\n",
    "        print(\"\\n4Ô∏è‚É£ PROPOZYCJA TYTU≈ÅU:\")\n",
    "        title_prompt = f\"Write a catchy title for this article: {summary_text[:100]}\"\n",
    "        title = self.generator(title_prompt, max_length=30, num_return_sequences=1)\n",
    "        print(title[0]['generated_text'].split('\\n')[0])\n",
    "        \n",
    "        return {\n",
    "            'summary': summary_text,\n",
    "            'sentiment': sentiment,\n",
    "        }\n",
    "\n",
    "# Test\n",
    "article_example = \"\"\"\n",
    "Breakthrough in renewable energy research was announced today. Scientists at MIT have \n",
    "developed a new solar panel technology that is 40% more efficient than current models. \n",
    "The innovation uses a novel material that can capture a broader spectrum of sunlight. \n",
    "This development could significantly reduce the cost of solar energy and accelerate \n",
    "the transition to clean energy sources. The research team plans to commercialize the \n",
    "technology within three years. Industry experts are calling this a game-changer for \n",
    "the renewable energy sector.\n",
    "\"\"\"\n",
    "\n",
    "# Inicjalizuj pipeline\n",
    "nlp_pipeline = NLPPipeline()\n",
    "\n",
    "# Analizuj artyku≈Ç\n",
    "questions = [\n",
    "    \"Who developed the new technology?\",\n",
    "    \"How much more efficient is the new solar panel?\",\n",
    "    \"When will the technology be commercialized?\"\n",
    "]\n",
    "\n",
    "results = nlp_pipeline.analyze_article(article_example, questions)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie Modu≈Çu 5\n",
    "\n",
    "‚úÖ Nauczyli≈õmy siƒô tworzyƒá podsumowania tekst√≥w (extractive i abstractive)\n",
    "\n",
    "‚úÖ Poznali≈õmy techniki generowania tre≈õci i kontroli parametr√≥w\n",
    "\n",
    "‚úÖ Zaimplementowali≈õmy automatyczne t≈Çumaczenia miƒôdzy jƒôzykami\n",
    "\n",
    "‚úÖ Przeprowadzili≈õmy zaawansowanƒÖ analizƒô sentymentu\n",
    "\n",
    "‚úÖ Stworzyli≈õmy system Question Answering\n",
    "\n",
    "‚úÖ Zbudowali≈õmy kompletny pipeline NLU/NLG\n",
    "\n",
    "### Kluczowe wnioski:\n",
    "- Modele Transformer umo≈ºliwiajƒÖ r√≥≈ºnorodne zadania NLP\n",
    "- Pipeline'y Hugging Face znacznie upraszczajƒÖ implementacjƒô\n",
    "- Ka≈ºde zadanie ma specyficzne modele i parametry\n",
    "- Jako≈õƒá zale≈ºy od wyboru odpowiedniego modelu i dostrojenia\n",
    "\n",
    "---\n",
    "\n",
    "**Nastƒôpny krok**: Modu≈Ç 6 - NLP w praktyce biznesowej (chatboty, automatyzacja)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
