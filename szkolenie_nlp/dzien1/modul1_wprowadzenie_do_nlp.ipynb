{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DzieÅ„ 1 - ModuÅ‚ 1: Wprowadzenie do NLP i jego zastosowaÅ„\n",
    "\n",
    "## Cele moduÅ‚u:\n",
    "- Zrozumienie czym jest przetwarzanie jÄ™zyka naturalnego (NLP)\n",
    "- Poznanie gÅ‚Ã³wnych zastosowaÅ„ NLP w praktyce\n",
    "- PorÃ³wnanie klasycznych i nowoczesnych podejÅ›Ä‡ do NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Czym jest NLP (Natural Language Processing)?\n",
    "\n",
    "**Natural Language Processing (NLP)** to dziedzina sztucznej inteligencji, ktÃ³ra zajmuje siÄ™ interakcjÄ… miÄ™dzy komputerami a jÄ™zykiem ludzkim.\n",
    "\n",
    "### GÅ‚Ã³wne cele NLP:\n",
    "- **Rozumienie** - analiza i interpretacja tekstu\n",
    "- **Generowanie** - tworzenie naturalnie brzmiÄ…cego tekstu\n",
    "- **PrzeksztaÅ‚canie** - tÅ‚umaczenia, podsumowania, parafrazy\n",
    "\n",
    "### Wyzwania w NLP:\n",
    "- WieloznacznoÅ›Ä‡ (ambiguity)\n",
    "- Kontekst i znaczenie ukryte\n",
    "- Idiomy i wyraÅ¼enia kulturowe\n",
    "- ZrÃ³Å¼nicowanie jÄ™zykowe (dialekty, slang)\n",
    "- BÅ‚Ä™dy ortograficzne i gramatyczne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 PrzeglÄ…d zastosowaÅ„ NLP\n",
    "\n",
    "### 1. Chatboty i Asystenci Wirtualni\n",
    "- ObsÅ‚uga klienta 24/7\n",
    "- Automatyczne odpowiedzi na FAQ\n",
    "- Rezerwacje i zamÃ³wienia\n",
    "- PrzykÅ‚ady: ChatGPT, Alexa, Siri, Google Assistant\n",
    "\n",
    "### 2. Analiza Sentymentu (Sentiment Analysis)\n",
    "- Analiza opinii klientÃ³w\n",
    "- Monitoring marki w social media\n",
    "- Analiza nastrojÃ³w na rynku\n",
    "- Ocena produktÃ³w i usÅ‚ug\n",
    "\n",
    "### 3. TÅ‚umaczenia Maszynowe\n",
    "- Google Translate, DeepL\n",
    "- TÅ‚umaczenia dokumentÃ³w\n",
    "- TÅ‚umaczenia w czasie rzeczywistym\n",
    "\n",
    "### 4. Podsumowania Tekstu\n",
    "- Automatyczne streszczenia artykuÅ‚Ã³w\n",
    "- Analiza dokumentÃ³w prawnych\n",
    "- Agregacja wiadomoÅ›ci\n",
    "\n",
    "### 5. Rozpoznawanie Nazwanych Encji (NER)\n",
    "- Ekstrakcja informacji z dokumentÃ³w\n",
    "- Identyfikacja osÃ³b, miejsc, organizacji\n",
    "- Analiza CV i ofert pracy\n",
    "\n",
    "### 6. Systemy PytaÅ„ i Odpowiedzi (Q&A)\n",
    "- Wyszukiwanie informacji w bazach wiedzy\n",
    "- Systemy help desk\n",
    "- Edukacyjne platformy e-learningowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prosty przykÅ‚ad - analiza sentymentu z uÅ¼yciem biblioteki TextBlob\n",
    "# (instalacja: pip install textblob)\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "# PrzykÅ‚adowe teksty w jÄ™zyku angielskim\n",
    "teksty = [\n",
    "    \"I love this product! It's amazing and works perfectly.\",\n",
    "    \"This is the worst experience I've ever had. Terrible!\",\n",
    "    \"The product is okay. Nothing special but does the job.\"\n",
    "]\n",
    "\n",
    "for tekst in teksty:\n",
    "    analiza = TextBlob(tekst)\n",
    "    sentiment = analiza.sentiment\n",
    "    \n",
    "    # Polarity: -1 (negatywny) do 1 (pozytywny)\n",
    "    if sentiment.polarity > 0.1:\n",
    "        kategoria = \"POZYTYWNY\"\n",
    "    elif sentiment.polarity < -0.1:\n",
    "        kategoria = \"NEGATYWNY\"\n",
    "    else:\n",
    "        kategoria = \"NEUTRALNY\"\n",
    "    \n",
    "    print(f\"Tekst: {tekst}\")\n",
    "    print(f\"Sentyment: {kategoria} (polarity: {sentiment.polarity:.2f})\")\n",
    "    print(\"-\" * 80)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Modele NLP: Klasyczne podejÅ›cia vs Nowoczesne architektury\n",
    "\n",
    "### Klasyczne podejÅ›cia (do ~2017)\n",
    "\n",
    "#### 1. Metody oparte na reguÅ‚ach\n",
    "- RÄ™cznie tworzone reguÅ‚y gramatyczne\n",
    "- SÅ‚owniki i wzorce\n",
    "- **Zalety**: Przewidywalne, Å‚atwe do debugowania\n",
    "- **Wady**: Trudne w skalowaniu, wymagajÄ… ekspertÃ³w\n",
    "\n",
    "#### 2. Bag of Words (BoW) i TF-IDF\n",
    "- Reprezentacja tekstu jako zbioru sÅ‚Ã³w\n",
    "- Utrata informacji o kolejnoÅ›ci\n",
    "- **Zalety**: Proste, szybkie\n",
    "- **Wady**: Brak kontekstu, duÅ¼a wymiarowoÅ›Ä‡\n",
    "\n",
    "#### 3. N-gramy\n",
    "- Sekwencje n kolejnych sÅ‚Ã³w\n",
    "- CzÄ™Å›ciowe zachowanie kontekstu\n",
    "- **Zalety**: Proste, dziaÅ‚ajÄ… lokalnie\n",
    "- **Wady**: Eksplozja wymiarowoÅ›ci\n",
    "\n",
    "#### 4. Word2Vec, GloVe (Word Embeddings)\n",
    "- Reprezentacja sÅ‚Ã³w jako wektorÃ³w\n",
    "- PodobieÅ„stwo semantyczne\n",
    "- **Zalety**: Znaczenie sÅ‚Ã³w, podobieÅ„stwo\n",
    "- **Wady**: Jedno znaczenie na sÅ‚owo\n",
    "\n",
    "### Nowoczesne architektury (od ~2017)\n",
    "\n",
    "#### 1. Architektury RNN/LSTM\n",
    "- Przetwarzanie sekwencyjne\n",
    "- PamiÄ™Ä‡ kontekstu\n",
    "- **Wady**: Wolne, problem z dÅ‚ugimi sekwencjami\n",
    "\n",
    "#### 2. Transformery (2017 - Attention is All You Need)\n",
    "- Mechanizm uwagi (attention)\n",
    "- Przetwarzanie rÃ³wnolegÅ‚e\n",
    "- **Zalety**: Szybkie, skalowalne, potÄ™Å¼ne\n",
    "\n",
    "#### 3. BERT (2018)\n",
    "- Bidirectional Encoder Representations\n",
    "- Rozumienie kontekstu z obu stron\n",
    "- Pre-training + Fine-tuning\n",
    "\n",
    "#### 4. GPT (2018-2024)\n",
    "- Generative Pre-trained Transformer\n",
    "- Generowanie tekstu\n",
    "- GPT-3, GPT-4 - modele ogÃ³lnego przeznaczenia\n",
    "\n",
    "#### 5. T5, BART, inne modele Seq2Seq\n",
    "- Wszystko jako zadanie text-to-text\n",
    "- Uniwersalne podejÅ›cie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PorÃ³wnanie: Klasyczne vs Nowoczesne\n",
    "\n",
    "| Aspekt | Klasyczne | Nowoczesne (Transformery) |\n",
    "|--------|-----------|---------------------------|\n",
    "| WydajnoÅ›Ä‡ | Åšrednia | Wysoka |\n",
    "| Zrozumienie kontekstu | Ograniczone | DoskonaÅ‚e |\n",
    "| Wymagania obliczeniowe | Niskie | Wysokie |\n",
    "| IloÅ›Ä‡ potrzebnych danych | MaÅ‚a-Åšrednia | DuÅ¼a (ale transfer learning!) |\n",
    "| InterpretowalnoÅ›Ä‡ | Wysoka | Niska |\n",
    "| Czas treningu | KrÃ³tki | DÅ‚ugi |\n",
    "| WszechstronnoÅ›Ä‡ | Niska | Wysoka |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# PrzykÅ‚ad: PorÃ³wnanie klasycznego i nowoczesnego podejÅ›cia\n",
    "\n",
    "# KLASYCZNE: Bag of Words z sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "dokumenty = [\n",
    "    \"LubiÄ™ programowaÄ‡ w Pythonie\",\n",
    "    \"Python to Å›wietny jÄ™zyk programowania\",\n",
    "    \"UczÄ™ siÄ™ sztucznej inteligencji\"\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(dokumenty)\n",
    "\n",
    "print(\"=== KLASYCZNE: Bag of Words ===\")\n",
    "print(\"SÅ‚ownik:\", vectorizer.get_feature_names_out())\n",
    "print(\"Reprezentacja macierzowa:\")\n",
    "print(X_bow.toarray())\n",
    "print()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# NOWOCZESNE: Embeddingi z Hugging Face\n",
    "# Uwaga: To tylko demonstracja - szczegÃ³Å‚y w Module 2!\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "# # ZaÅ‚aduj model i tokenizer (HerBERT dla jÄ™zyka polskiego)\n",
    "# model_name = \"allegro/herbert-base-cased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# tekst = \"LubiÄ™ programowaÄ‡ w Pythonie\"\n",
    "\n",
    "# # Tokenizacja\n",
    "# inputs = tokenizer(tekst, return_tensors=\"pt\")\n",
    "\n",
    "# # Uzyskanie embeddingÃ³w\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)\n",
    "#     embeddings = outputs.last_hidden_state\n",
    "\n",
    "# print(\"=== NOWOCZESNE: Transformer Embeddings ===\")\n",
    "# print(f\"Shape embeddingÃ³w: {embeddings.shape}\")\n",
    "# print(f\"KaÅ¼de sÅ‚owo reprezentowane przez wektor {embeddings.shape[-1]} wymiarÃ³w\")\n",
    "\n",
    "print(\"\\nðŸ“ Nowoczesne modele przeanalizujemy szczegÃ³Å‚owo w kolejnych moduÅ‚ach!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ä†wiczenie praktyczne\n",
    "\n",
    "**Zadanie**: ZastanÃ³w siÄ™ nad wÅ‚asnym projektem NLP\n",
    "\n",
    "1. Jakie zastosowanie NLP byÅ‚oby przydatne w Twojej pracy/firmie?\n",
    "2. Jakie dane tekstowe sÄ… dostÄ™pne?\n",
    "3. Czy potrzebujesz rozumienia czy generowania tekstu?\n",
    "4. Jakie metryki sukcesu byÅ‚yby waÅ¼ne?\n",
    "\n",
    "Zapisz swoje przemyÅ›lenia poniÅ¼ej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Miejsce na Twoje notatki i pomysÅ‚y\n",
    "\n",
    "moj_projekt = {\n",
    "    \"zastosowanie\": \"...\",\n",
    "    \"dostepne_dane\": \"...\",\n",
    "    \"typ_zadania\": \"...\",  # np. klasyfikacja, generowanie, NER, itp.\n",
    "    \"metryki\": \"...\"  # np. dokÅ‚adnoÅ›Ä‡, precyzja, satysfakcja uÅ¼ytkownikÃ³w\n",
    "}\n",
    "\n",
    "print(moj_projekt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie ModuÅ‚u 1\n",
    "\n",
    "âœ… PoznaliÅ›my definicjÄ™ i cele NLP\n",
    "\n",
    "âœ… PrzejrzeliÅ›my gÅ‚Ã³wne zastosowania (chatboty, sentiment, tÅ‚umaczenia, itp.)\n",
    "\n",
    "âœ… ZrozumieliÅ›my ewolucjÄ™ od klasycznych metod do TransformerÃ³w\n",
    "\n",
    "âœ… ZobaczyliÅ›my proste przykÅ‚ady w praktyce\n",
    "\n",
    "---\n",
    "\n",
    "**NastÄ™pny krok**: ModuÅ‚ 2 - NarzÄ™dzia i biblioteki do NLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
