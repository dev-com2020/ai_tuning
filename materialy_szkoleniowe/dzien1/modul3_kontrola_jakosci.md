# Modu≈Ç 3: Kontrolowanie jako≈õci i bezpiecze≈Ñstwa generowanych tre≈õci

## Cel modu≈Çu
Po zako≈Ñczeniu tego modu≈Çu uczestnik bƒôdzie:
- Rozumia≈Ç i stosowa≈Ç metody ograniczania halucynacji
- Kontrolowa≈Ç styl, ton i zakres generowanych tre≈õci  
- Implementowa≈Ç zabezpieczenia i moderacjƒô automatycznƒÖ
- Projektowa≈Ç bezpieczne systemy oparte na LLM

## 1. Metody ograniczania ryzyka halucynacji

### 1.1 Zrozumienie problemu halucynacji

**Definicja**: Halucynacje to sytuacje, gdy model generuje informacje brzmiƒÖce przekonujƒÖco, ale nieprawdziwe lub nieistniejƒÖce.

**Typy halucynacji**:
1. **Faktyczne** - nieprawdziwe fakty, daty, liczby
2. **≈πr√≥d≈Çowe** - nieistniejƒÖce cytaty, publikacje
3. **Logiczne** - b≈Çƒôdne wnioskowanie
4. **Temporalne** - anachronizmy, b≈Çƒôdne sekwencje

### 1.2 Parametry kontrolujƒÖce generowanie

#### Temperature (Temperatura)
Kontroluje losowo≈õƒá/kreatywno≈õƒá odpowiedzi.

```python
# Temperature = 0 (deterministyczne)
prompt = "Stolica Polski to"
# Odpowied≈∫: "Warszawa" (zawsze ta sama)

# Temperature = 0.7 (zbalansowane)  
prompt = "Napisz kr√≥tkƒÖ historiƒô o kocie"
# Odpowied≈∫: Zr√≥≈ºnicowana, ale sensowna

# Temperature = 1.5 (bardzo kreatywne)
prompt = "Wymy≈õl nowe s≈Çowo i jego definicjƒô"
# Odpowied≈∫: Bardzo kreatywna, mo≈ºe byƒá chaotyczna
```

**Zastosowania Temperature**:
- `0.0 - 0.3`: Fakty, analizy, odpowiedzi techniczne
- `0.4 - 0.7`: Og√≥lne zastosowania, balans
- `0.8 - 1.0`: Kreatywne pisanie, brainstorming
- `1.0+`: Eksperymentalne, bardzo kreatywne

#### Top-p (Nucleus Sampling)
Wybiera tokeny z g√≥rnego percentyla prawdopodobie≈Ñstwa.

```python
# Top-p = 0.1 (bardzo restrykcyjne)
# Wybiera tylko z top 10% najbardziej prawdopodobnych token√≥w

# Top-p = 0.9 (standardowe)
# Wybiera z token√≥w sumujƒÖcych siƒô do 90% prawdopodobie≈Ñstwa

# Top-p = 1.0 (wszystkie tokeny)
# Brak ogranicze≈Ñ
```

#### Frequency Penalty
Karze za powtarzanie token√≥w.

```python
# Frequency Penalty = 0 (brak kary)
"Kot kot kot mo≈ºe powtarzaƒá kot"

# Frequency Penalty = 0.5 (≈õrednia kara)
"Kot jest zwierzƒôciem, kt√≥re lubi mleko i zabawy"

# Frequency Penalty = 2.0 (silna kara)
"Kot to zwierzƒô domowe lubiƒÖce mleko, zabawy oraz polowania"
```

#### Presence Penalty
Karze za u≈ºywanie token√≥w, kt√≥re ju≈º wystƒÖpi≈Çy.

```python
# Presence Penalty = 0
"Lubiƒô pizzƒô. Pizza jest dobra. Jem pizzƒô codziennie."

# Presence Penalty = 0.6
"Lubiƒô pizzƒô. Ta w≈Çoska potrawa jest pyszna. Jem jƒÖ czƒôsto."

# Presence Penalty = 2.0  
"Kocham pizzƒô. W≈Çoskie danie zachwyca smakiem. Delektujƒô siƒô regularnie."
```

### 1.3 Techniki promptowe redukujƒÖce halucynacje

#### 1. Explicit Uncertainty Instructions
```
"Je≈õli nie znasz odpowiedzi, napisz 'Nie mam pewno≈õci' lub 'Nie posiadam tej informacji'.
Nie zgaduj i nie wymy≈õlaj fakt√≥w."
```

#### 2. Source Request
```
"Dla ka≈ºdego podanego faktu, podaj ≈∫r√≥d≈Ço lub zaznacz ≈ºe jest to og√≥lna wiedza.
Format: [Fakt] (≈πr√≥d≈Ço: ...)"
```

#### 3. Step-by-Step Verification
```
"Zanim odpowiesz:
1. Zidentyfikuj fakty w pytaniu
2. Sprawd≈∫ swojƒÖ wiedzƒô o ka≈ºdym
3. Zaznacz poziom pewno≈õci (Wysoki/≈öredni/Niski)
4. Odpowiedz tylko u≈ºywajƒÖc fakt√≥w z wysokƒÖ pewno≈õciƒÖ"
```

#### 4. Fact-Checking Prompt
```
"Po wygenerowaniu odpowiedzi, przejrzyj jƒÖ i:
1. Oznacz wszystkie stwierdzenia faktyczne [F]
2. Oce≈Ñ prawdopodobie≈Ñstwo ka≈ºdego (0-100%)
3. Usu≈Ñ lub zmodyfikuj stwierdzenia <70%"
```

### 1.4 Implementacja walidacji

```python
class HallucinationDetector:
    def __init__(self):
        self.fact_patterns = [
            r'\d{4}',  # years
            r'\d+%',   # percentages
            r'\"[^\"]+\"',  # quotes
            r'wed≈Çug \w+',  # citations
        ]
        
    def flag_potential_hallucinations(self, text):
        flags = []
        for pattern in self.fact_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                flags.append({
                    'text': match,
                    'type': 'potential_fact',
                    'confidence': self.assess_confidence(match)
                })
        return flags
    
    def assess_confidence(self, fact):
        # Implementacja oceny pewno≈õci
        return 0.5  # placeholder
```

## 2. Kontrolowanie stylu, tonu i zakresu

### 2.1 Definiowanie stylu

#### Komponenty stylu:
1. **Formalno≈õƒá**
   ```
   Formalny: "Szanowni Pa≈Ñstwo, pragnƒô przedstawiƒá..."
   Neutralny: "Chcia≈Çbym przedstawiƒá..."
   Nieformalny: "Hej, poka≈ºƒô wam..."
   ```

2. **Techniczny poziom**
   ```
   Ekspert: "Implementacja algorytmu wykorzystuje O(n log n)..."
   ≈öredni: "Program sortuje dane efektywnie..."
   Podstawowy: "Program uk≈Çada rzeczy w kolejno≈õci..."
   ```

3. **Emocjonalno≈õƒá**
   ```
   Empatyczny: "Rozumiem, ≈ºe to mo≈ºe byƒá frustrujƒÖce..."
   Neutralny: "Problem zosta≈Ç zidentyfikowany..."
   Dystansowany: "Nale≈ºy rozwiƒÖzaƒá nastƒôpujƒÖcƒÖ kwestiƒô..."
   ```

### 2.2 Instrukcje stylowe

```python
style_instructions = {
    "corporate_formal": """
    Styl: Korporacyjny, profesjonalny
    - U≈ºywaj pe≈Çnych zda≈Ñ i poprawnej gramatyki
    - Unikaj skr√≥t√≥w i kolokwializm√≥w
    - Zwracaj siƒô per "Pa≈Ñstwo" lub "Pan/Pani"
    - U≈ºywaj strony biernej gdy to stosowne
    """,
    
    "friendly_casual": """
    Styl: Przyjazny, swobodny
    - U≈ºywaj prostego, zrozumia≈Çego jƒôzyka
    - Mo≈ºesz u≈ºywaƒá "ty" i skr√≥t√≥w
    - Dodawaj emotikony gdzie stosowne üòä
    - BƒÖd≈∫ entuzjastyczny i pozytywny
    """,
    
    "technical_documentation": """
    Styl: Techniczny, precyzyjny
    - U≈ºywaj terminologii bran≈ºowej
    - Strukturyzuj informacje (punkty, sekcje)
    - Podawaj konkretne przyk≈Çady kodu
    - Unikaj niepotrzebnych ozdobnik√≥w
    """
}
```

### 2.3 Kontrola tonu

```python
class ToneController:
    def __init__(self):
        self.tone_markers = {
            'enthusiastic': ['wspaniale', 'fantastycznie', 'ekscytujƒÖce', '!'],
            'professional': ['proszƒô', 'uprzejmie', 'z powa≈ºaniem'],
            'empathetic': ['rozumiem', 'wsp√≥≈Çczujƒô', 'przykro mi'],
            'authoritative': ['nale≈ºy', 'wymaga siƒô', 'obowiƒÖzkowo']
        }
    
    def apply_tone(self, prompt, tone):
        tone_instruction = f"\nTon wypowiedzi: {tone}"
        tone_examples = f"\nU≈ºywaj s≈Ç√≥w takich jak: {', '.join(self.tone_markers.get(tone, []))}"
        return prompt + tone_instruction + tone_examples
```

### 2.4 Ograniczanie zakresu

#### Content Boundaries
```
"Ograniczenia tematyczne:
- Odpowiadaj TYLKO na pytania zwiƒÖzane z [TEMAT]
- Je≈õli pytanie wykracza poza zakres, grzecznie przekieruj
- Nie poruszaj temat√≥w: [LISTA ZAKAZANYCH]
- Przyk≈Çad przekierowania: 'Skupmy siƒô na [TEMAT]...'"
```

#### Length Control
```python
def create_length_controlled_prompt(content, min_words=50, max_words=200):
    return f"""
    {content}
    
    Wymagania dotyczƒÖce d≈Çugo≈õci:
    - Minimum {min_words} s≈Ç√≥w
    - Maximum {max_words} s≈Ç√≥w
    - Je≈õli temat wymaga wiƒôcej, podsumuj kluczowe punkty
    """
```

#### Format Enforcement
```python
response_formats = {
    "bullet_points": """
    Format odpowiedzi:
    ‚Ä¢ Punkt pierwszy
    ‚Ä¢ Punkt drugi
    ‚Ä¢ Ka≈ºdy punkt max 2 zdania
    """,
    
    "numbered_steps": """
    Format odpowiedzi:
    1. Krok pierwszy (co zrobiƒá)
       - Szczeg√≥≈Ç A
       - Szczeg√≥≈Ç B
    2. Krok drugi (kolejna akcja)
    """,
    
    "qa_format": """
    Format odpowiedzi:
    P: [Pytanie]
    O: [Odpowied≈∫ - max 3 zdania]
    """
}
```

## 3. Implementacja zabezpiecze≈Ñ

### 3.1 Moderacja automatyczna

```python
class ContentModerator:
    def __init__(self):
        self.blocked_terms = set()
        self.sensitive_topics = []
        self.toxicity_threshold = 0.7
        
    def moderate_input(self, text):
        """Sprawdza input u≈ºytkownika przed wys≈Çaniem do LLM"""
        issues = []
        
        # Sprawdzenie blocked terms
        for term in self.blocked_terms:
            if term.lower() in text.lower():
                issues.append(f"Blocked term: {term}")
        
        # Sprawdzenie prompt injection
        if self.detect_prompt_injection(text):
            issues.append("Potential prompt injection detected")
            
        # Sprawdzenie d≈Çugo≈õci
        if len(text) > 10000:
            issues.append("Input too long")
            
        return issues
    
    def moderate_output(self, text):
        """Sprawdza output LLM przed zwr√≥ceniem u≈ºytkownikowi"""
        issues = []
        
        # Sprawdzenie toksyczno≈õci
        toxicity = self.calculate_toxicity(text)
        if toxicity > self.toxicity_threshold:
            issues.append(f"High toxicity: {toxicity}")
        
        # Sprawdzenie PII (Personal Identifiable Information)
        if self.detect_pii(text):
            issues.append("PII detected")
            
        return issues
    
    def detect_prompt_injection(self, text):
        """Wykrywa pr√≥by prompt injection"""
        injection_patterns = [
            "ignore previous instructions",
            "disregard all prior",
            "new instructions:",
            "system: ",
            "[[INST]]",
        ]
        return any(pattern in text.lower() for pattern in injection_patterns)
    
    def detect_pii(self, text):
        """Wykrywa dane osobowe"""
        patterns = {
            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'phone': r'\b\d{3}[-.]?\d{3}[-.]?\d{3}\b',
            'pesel': r'\b\d{11}\b',
            'credit_card': r'\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b'
        }
        
        for pii_type, pattern in patterns.items():
            if re.search(pattern, text):
                return True
        return False
```

### 3.2 Filtrowanie tre≈õci

```python
class ContentFilter:
    def __init__(self):
        self.filters = {
            'violence': self.filter_violence,
            'adult': self.filter_adult_content,
            'medical': self.filter_medical_advice,
            'financial': self.filter_financial_advice,
            'legal': self.filter_legal_advice
        }
    
    def apply_filters(self, content, active_filters):
        """Aplikuje wybrane filtry do tre≈õci"""
        filtered_content = content
        applied_filters = []
        
        for filter_name in active_filters:
            if filter_name in self.filters:
                filtered_content, was_filtered = self.filters[filter_name](filtered_content)
                if was_filtered:
                    applied_filters.append(filter_name)
        
        return filtered_content, applied_filters
    
    def filter_medical_advice(self, content):
        """Filtruje porady medyczne"""
        medical_keywords = ['diagnoza', 'leczenie', 'dawkowanie', 'choroba']
        
        if any(keyword in content.lower() for keyword in medical_keywords):
            disclaimer = "\n\n‚ö†Ô∏è Uwaga: To nie jest porada medyczna. Skonsultuj siƒô z lekarzem."
            return content + disclaimer, True
        
        return content, False
```

### 3.3 Walidacja odpowiedzi

```python
class ResponseValidator:
    def __init__(self):
        self.validation_rules = []
    
    def add_rule(self, rule_name, validation_func):
        """Dodaje regu≈Çƒô walidacji"""
        self.validation_rules.append({
            'name': rule_name,
            'func': validation_func
        })
    
    def validate(self, response):
        """Waliduje odpowied≈∫ wed≈Çug wszystkich regu≈Ç"""
        validation_results = {
            'is_valid': True,
            'failed_rules': [],
            'warnings': []
        }
        
        for rule in self.validation_rules:
            result = rule['func'](response)
            if not result['passed']:
                validation_results['is_valid'] = False
                validation_results['failed_rules'].append(rule['name'])
            if 'warning' in result:
                validation_results['warnings'].append(result['warning'])
        
        return validation_results

# Przyk≈Çadowe regu≈Çy walidacji
def validate_no_urls(response):
    """Sprawdza czy odpowied≈∫ nie zawiera URL"""
    url_pattern = r'https?://\S+'
    if re.search(url_pattern, response):
        return {'passed': False, 'message': 'URLs not allowed'}
    return {'passed': True}

def validate_language(response, allowed_lang='pl'):
    """Sprawdza jƒôzyk odpowiedzi"""
    # Simplified - w praktyce u≈ºyj biblioteki do detekcji jƒôzyka
    if allowed_lang == 'pl' and not any(char in response for char in 'ƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º'):
        return {'passed': False, 'warning': 'Response might not be in Polish'}
    return {'passed': True}
```

### 3.4 System bezpiecze≈Ñstwa end-to-end

```python
class SecureLLMSystem:
    def __init__(self, llm_client):
        self.llm = llm_client
        self.moderator = ContentModerator()
        self.filter = ContentFilter()
        self.validator = ResponseValidator()
        self.audit_log = []
        
    def process_request(self, user_input, user_id=None):
        """Bezpieczne przetwarzanie zapytania"""
        request_id = str(uuid.uuid4())
        
        # 1. Logowanie
        self.log_request(request_id, user_id, user_input)
        
        # 2. Moderacja inputu
        input_issues = self.moderator.moderate_input(user_input)
        if input_issues:
            return self.handle_blocked_input(input_issues)
        
        # 3. Przygotowanie bezpiecznego promptu
        safe_prompt = self.prepare_safe_prompt(user_input)
        
        # 4. Wywo≈Çanie LLM
        try:
            response = self.llm.generate(
                safe_prompt,
                temperature=0.3,  # Niska dla bezpiecze≈Ñstwa
                max_tokens=500    # Limit d≈Çugo≈õci
            )
        except Exception as e:
            return self.handle_llm_error(e)
        
        # 5. Moderacja outputu
        output_issues = self.moderator.moderate_output(response)
        if output_issues:
            response = self.sanitize_response(response, output_issues)
        
        # 6. Filtrowanie
        response, applied_filters = self.filter.apply_filters(
            response, 
            ['medical', 'financial', 'legal']
        )
        
        # 7. Walidacja ko≈Ñcowa
        validation = self.validator.validate(response)
        if not validation['is_valid']:
            response = self.handle_validation_failure(response, validation)
        
        # 8. Logowanie odpowiedzi
        self.log_response(request_id, response, applied_filters)
        
        return {
            'response': response,
            'metadata': {
                'filtered': len(applied_filters) > 0,
                'warnings': validation.get('warnings', [])
            }
        }
    
    def prepare_safe_prompt(self, user_input):
        """Przygotowuje bezpieczny prompt"""
        return f"""
        Jeste≈õ pomocnym asystentem. Przestrzegaj nastƒôpujƒÖcych zasad:
        1. Nie generuj tre≈õci szkodliwych, obra≈∫liwych lub nielegalnych
        2. Nie udostƒôpniaj danych osobowych
        3. Nie udzielaj porad medycznych, prawnych ani finansowych
        4. BƒÖd≈∫ pomocny i profesjonalny
        
        Zapytanie u≈ºytkownika: {user_input}
        """
```

## 4. Praktyczne przyk≈Çady implementacji

### 4.1 Bezpieczny chatbot korporacyjny

```python
class CorporateChatbot:
    def __init__(self):
        self.system_prompt = """
        Jeste≈õ asystentem korporacyjnym firmy TechCorp.
        
        ZASADY:
        1. Odpowiadaj TYLKO na pytania zwiƒÖzane z firmƒÖ
        2. U≈ºywaj formalnego, profesjonalnego tonu
        3. Nie ujawniaj informacji poufnych
        4. Przekierowuj pytania HR do dzia≈Çu kadr
        5. Nie komentuj konkurencji
        
        DOZWOLONE TEMATY:
        - Produkty i us≈Çugi firmy
        - Godziny otwarcia i kontakt
        - Og√≥lne informacje o firmie
        - Publiczne osiƒÖgniƒôcia
        
        NIEDOZWOLONE:
        - Dane finansowe szczeg√≥≈Çowe
        - Informacje o pracownikach
        - Plany strategiczne
        - Krytyka konkurencji
        """
        
        self.topic_redirects = {
            'hr': "W sprawach kadrowych proszƒô kontaktowaƒá siƒô z dzia≈Çem HR: hr@techcorp.com",
            'finance': "Szczeg√≥≈Çowe dane finansowe dostƒôpne sƒÖ w raportach gie≈Çdowych",
            'competitor': "Skupiamy siƒô na naszych produktach i warto≈õci dla klient√≥w"
        }
```

### 4.2 System analizy sentymentu z kontrolƒÖ jako≈õci

```python
class SentimentAnalyzer:
    def __init__(self):
        self.calibration_examples = {
            'positive': [
                "≈öwietny produkt! Polecam ka≈ºdemu.",
                "Jestem zachwycony jako≈õciƒÖ obs≈Çugi."
            ],
            'neutral': [
                "Produkt spe≈Çnia swojƒÖ funkcjƒô.",
                "Dostawa przysz≈Ça na czas."
            ],
            'negative': [
                "Rozczarowanie. Nie polecam.",
                "S≈Çaba jako≈õƒá za tƒô cenƒô."
            ]
        }
    
    def analyze_with_confidence(self, text):
        prompt = f"""
        Przeanalizuj sentyment nastƒôpujƒÖcego tekstu.
        
        Przyk≈Çady kalibracyjne:
        POZYTYWNY: {self.calibration_examples['positive'][0]}
        NEUTRALNY: {self.calibration_examples['neutral'][0]}
        NEGATYWNY: {self.calibration_examples['negative'][0]}
        
        Tekst do analizy: "{text}"
        
        Odpowiedz w formacie:
        Sentyment: [POZYTYWNY/NEUTRALNY/NEGATYWNY]
        Pewno≈õƒá: [0-100]%
        Kluczowe frazy: [lista fraz wp≈ÇywajƒÖcych na ocenƒô]
        """
        
        return self.parse_sentiment_response(prompt)
```

### 4.3 Generator raport√≥w z kontrolƒÖ fakt√≥w

```python
class ReportGenerator:
    def __init__(self):
        self.fact_check_prompt = """
        GenerujƒÖc raport, stosuj nastƒôpujƒÖce zasady:
        
        1. Dla ka≈ºdego stwierdzenia liczbowego dodaj [FAKT] lub [SZACUNEK]
        2. Unikaj stwierdze≈Ñ bez podstaw - u≈ºyj "prawdopodobnie", "oko≈Ço", "szacunkowo"
        3. Je≈õli brakuje danych, napisz [BRAK DANYCH]
        4. U≈ºywaj zakresu zamiast konkretnych liczb gdy nie masz pewno≈õci
        
        Format:
        - U≈ºyj nag≈Ç√≥wk√≥w dla sekcji
        - Punktuj kluczowe wnioski
        - Dodaj sekcjƒô "Zastrze≈ºenia" na ko≈Ñcu
        """
    
    def generate_report(self, data, report_type):
        enhanced_prompt = f"""
        {self.fact_check_prompt}
        
        Typ raportu: {report_type}
        Dane wej≈õciowe: {data}
        
        Wygeneruj raport przestrzegajƒÖc wszystkich zasad bezpiecze≈Ñstwa.
        """
        
        report = self.llm.generate(enhanced_prompt, temperature=0.2)
        return self.post_process_report(report)
    
    def post_process_report(self, report):
        """Dodaje dodatkowe zabezpieczenia do raportu"""
        # Dodaj timestamp
        report = f"Raport wygenerowany: {datetime.now()}\n\n{report}"
        
        # Dodaj disclaimer
        disclaimer = """
        
        ---
        UWAGA: Ten raport zosta≈Ç wygenerowany automatycznie. 
        Zaleca siƒô weryfikacjƒô kluczowych danych przed podjƒôciem decyzji biznesowych.
        """
        
        return report + disclaimer
```

## 5. ƒÜwiczenia praktyczne

### ƒÜwiczenie 1: Kalibracja parametr√≥w
1. Wybierz zadanie (np. generowanie opisu produktu)
2. Przetestuj r√≥≈ºne kombinacje:
   - Temperature: 0, 0.3, 0.7, 1.0
   - Top-p: 0.5, 0.9, 1.0
3. Oce≈Ñ wyniki pod kƒÖtem:
   - Kreatywno≈õci
   - Sp√≥jno≈õci
   - Faktualno≈õci
4. Znajd≈∫ optymalne ustawienia

### ƒÜwiczenie 2: Detekcja halucynacji
1. Stw√≥rz prompt proszƒÖcy o:
   - Cytat z nieistniejƒÖcej ksiƒÖ≈ºki
   - Dane statystyczne z przysz≈Ço≈õci
   - Szczeg√≥≈Çy nieistniejƒÖcego wydarzenia
2. Analizuj jak model reaguje
3. Dodaj instrukcje anti-halucynacyjne
4. Por√≥wnaj wyniki

### ƒÜwiczenie 3: Implementacja moderatora
1. Zaimplementuj prosty system moderacji:
   - Lista zakazanych s≈Ç√≥w
   - Detekcja prompt injection
   - Sprawdzanie d≈Çugo≈õci
2. Przetestuj na r√≥≈ºnych inputach
3. Dodaj logowanie zdarze≈Ñ
4. Oce≈Ñ false positives/negatives

### ƒÜwiczenie 4: Kontrola stylu
1. Wybierz temat (np. "Sztuczna inteligencja")
2. Wygeneruj ten sam content w 4 stylach:
   - Akademicki
   - Biznesowy
   - Casual/blog
   - Dla dzieci
3. Analizuj r√≥≈ºnice
4. Stw√≥rz "style guide" dla ka≈ºdego

## 6. Case study: Bezpieczny chatbot medyczny

```python
class MedicalChatbot:
    def __init__(self):
        self.strict_prompt = """
        KRYTYCZNE: Jeste≈õ asystentem informacyjnym, NIE lekarzem.
        
        ABSOLUTNIE ZAKAZANE:
        - Diagnozowanie chor√≥b
        - Zalecanie lek√≥w lub dawkowania  
        - Interpretacja wynik√≥w bada≈Ñ
        - Odradzanie wizyty u lekarza
        
        DOZWOLONE:
        - Og√≥lne informacje o zdrowiu
        - Wyja≈õnianie termin√≥w medycznych
        - Informacje o zdrowym stylu ≈ºycia
        - Zachƒôcanie do konsultacji z lekarzem
        
        KA≈ªDA odpowied≈∫ MUSI zawieraƒá:
        "To nie jest porada medyczna. Skonsultuj siƒô z lekarzem."
        """
    
    def process_medical_query(self, query):
        # Sprawd≈∫ czy pytanie dotyczy konkretnych objaw√≥w
        symptom_keywords = ['boli', 'bolƒô', 'objawy', 'choroba', 'leczenie']
        
        if any(keyword in query.lower() for keyword in symptom_keywords):
            return self.redirect_to_doctor(query)
        
        # Standardowe przetwarzanie z disclaimerem
        response = self.generate_safe_response(query)
        return self.add_medical_disclaimer(response)
    
    def redirect_to_doctor(self, query):
        return """
        Opisywane objawy wymagajƒÖ profesjonalnej oceny medycznej.
        
        Co mo≈ºesz zrobiƒá:
        1. Skontaktuj siƒô z lekarzem pierwszego kontaktu
        2. W nag≈Çych przypadkach - zadzwo≈Ñ na 112
        3. Teleporada - wiele przychodni oferuje konsultacje online
        
        ‚ö†Ô∏è To nie jest porada medyczna. Tylko lekarz mo≈ºe postawiƒá diagnozƒô.
        """
```

## 7. Metryki i monitoring

### 7.1 KPIs bezpiecze≈Ñstwa

```python
class SafetyMetrics:
    def __init__(self):
        self.metrics = {
            'hallucination_rate': 0,
            'blocked_requests': 0,
            'filtered_responses': 0,
            'user_complaints': 0,
            'false_positives': 0
        }
    
    def calculate_safety_score(self):
        """Oblicza og√≥lny wska≈∫nik bezpiecze≈Ñstwa"""
        weights = {
            'hallucination_rate': -0.3,
            'blocked_requests': -0.1,
            'filtered_responses': -0.1,
            'user_complaints': -0.4,
            'false_positives': -0.1
        }
        
        score = 100
        for metric, value in self.metrics.items():
            score += weights.get(metric, 0) * value
            
        return max(0, min(100, score))
```

### 7.2 Dashboard monitoringu

```python
def create_safety_dashboard():
    """Tworzy dashboard do monitorowania bezpiecze≈Ñstwa"""
    return {
        'real_time_metrics': {
            'active_sessions': get_active_sessions(),
            'requests_per_minute': calculate_rpm(),
            'current_alerts': get_active_alerts()
        },
        'daily_stats': {
            'total_requests': get_daily_requests(),
            'blocked_percentage': calculate_block_rate(),
            'average_response_time': get_avg_response_time(),
            'user_satisfaction': get_satisfaction_score()
        },
        'top_issues': {
            'blocked_patterns': get_top_blocked_patterns(),
            'common_hallucinations': get_hallucination_patterns(),
            'user_complaints': get_complaint_categories()
        }
    }
```

## 8. Najlepsze praktyki

### 8.1 Checklist bezpiecze≈Ñstwa

- [ ] Zdefiniowano system prompt z jasnymi ograniczeniami
- [ ] Zaimplementowano walidacjƒô inputu
- [ ] Skonfigurowano moderacjƒô outputu
- [ ] Ustawiono odpowiednie parametry (temperature, max_tokens)
- [ ] Dodano disclaimery gdzie potrzebne
- [ ] Zaimplementowano logowanie
- [ ] Przygotowano obs≈Çugƒô b≈Çƒôd√≥w
- [ ] Przetestowano edge cases
- [ ] Skonfigurowano monitoring
- [ ] Przygotowano procedury eskalacji

### 8.2 Continuous Improvement

```python
class SafetyImprovement:
    def analyze_incidents(self, timeframe='7d'):
        """Analizuje incydenty bezpiecze≈Ñstwa"""
        incidents = self.get_incidents(timeframe)
        
        patterns = {
            'prompt_injection': [],
            'hallucinations': [],
            'toxic_content': [],
            'pii_leaks': []
        }
        
        for incident in incidents:
            category = self.categorize_incident(incident)
            patterns[category].append(incident)
        
        return self.generate_improvement_recommendations(patterns)
```

## 9. Podsumowanie

1. **Bezpiecze≈Ñstwo to proces ciƒÖg≈Çy, nie jednorazowa konfiguracja**
2. **Parametry modelu znaczƒÖco wp≈ÇywajƒÖ na jako≈õƒá i bezpiecze≈Ñstwo**
3. **Wielowarstwowe zabezpieczenia sƒÖ najskuteczniejsze**
4. **Monitoring i analiza sƒÖ kluczowe dla utrzymania bezpiecze≈Ñstwa**
5. **Transparentno≈õƒá (disclaimery) buduje zaufanie u≈ºytkownik√≥w**

## 10. Zadanie praktyczne

Zaprojektuj i zaimplementuj bezpieczny system chatbota dla banku:

1. **Wymagania**:
   - Obs≈Çuga pyta≈Ñ o produkty bankowe
   - Brak dostƒôpu do danych klient√≥w
   - Przekierowanie do konsultanta gdy trzeba
   - Detekcja pr√≥b wy≈Çudzenia informacji

2. **Implementacja**:
   - System prompt z ograniczeniami
   - Moderacja input/output
   - Filtrowanie danych wra≈ºliwych
   - System logowania

3. **Testy**:
   - 10 normalnych zapyta≈Ñ
   - 5 pr√≥b prompt injection
   - 5 pyta≈Ñ o dane wra≈ºliwe
   - Analiza wynik√≥w

## Materia≈Çy dodatkowe

- "Red Teaming Language Models" - Anthropic
- "Best Practices for Deploying Language Models" - Google
- "Content Moderation with LLMs" - OpenAI
- "AI Safety Fundamentals" - DeepMind