# PrzykÅ‚ady kodu AI i MCP

Ten katalog zawiera praktyczne przykÅ‚ady implementacji AI i MCP dla rÃ³Å¼nych zastosowaÅ„.

## ğŸ“‚ Struktura

```
przyklady/
â”œâ”€â”€ fine-tuning-examples.py    # PrzykÅ‚ady fine-tuningu modeli
â”œâ”€â”€ mcp-server-example.js      # PrzykÅ‚adowy serwer MCP
â”œâ”€â”€ README.md                  # Ten plik
â””â”€â”€ projects/                  # PrzykÅ‚adowe projekty
    â”œâ”€â”€ chatbot/              # Chatbot z AI
    â”œâ”€â”€ code-assistant/       # Asystent programisty
    â””â”€â”€ data-analyzer/        # Analizator danych
```

## ğŸ¯ PrzykÅ‚ady fine-tuningu (fine-tuning-examples.py)

### 1. Podstawowy fine-tuning
```python
from przyklady.fine_tuning_examples import UniversalFineTuner

# Inicjalizacja
tuner = UniversalFineTuner("microsoft/phi-2")

# ZaÅ‚aduj model z LoRA
tuner.load_model(use_lora=True)

# Przygotuj dane
dataset = tuner.prepare_dataset("data.json", format_type="instruction")

# Trenuj
tuner.train(dataset, epochs=3)
```

### 2. Fine-tuning dla rÃ³Å¼nych zadaÅ„

#### Klasyfikacja tekstu
```python
# Sentiment analysis
sentiment_data = [
    {"text": "Åšwietny produkt!", "label": 1},
    {"text": "Bardzo sÅ‚aba jakoÅ›Ä‡", "label": 0}
]

# Model BERT dla polskiego
model_name = "allegro/herbert-base-cased"
# ... zobacz przykÅ‚ad w pliku
```

#### Generowanie kodu
```python
# Dataset z przykÅ‚adami kodu
code_data = [
    {
        "instruction": "Napisz funkcjÄ™ sortujÄ…cÄ…",
        "input": "lista = [3, 1, 4, 1, 5]",
        "output": "def sort_list(lst):\n    return sorted(lst)"
    }
]
```

## ğŸ”§ PrzykÅ‚ady MCP (mcp-server-example.js)

### Podstawowy serwer MCP
```javascript
import { Server } from '@modelcontextprotocol/sdk/server/index.js';

const server = new Server({
  name: 'my-server',
  version: '1.0.0'
});

// Dodaj narzÄ™dzie
server.setRequestHandler('tools/list', async () => ({
  tools: [{
    name: 'hello',
    description: 'Przywitaj siÄ™',
    inputSchema: { /* ... */ }
  }]
}));
```

### Zaawansowane funkcje MCP

#### 1. Analiza plikÃ³w
```javascript
// NarzÄ™dzie do analizy kodu
{
  name: 'analyze_file',
  description: 'Analizuje plik i zwraca statystyki',
  inputSchema: {
    type: 'object',
    properties: {
      path: { type: 'string' },
      detailed: { type: 'boolean' }
    }
  }
}
```

#### 2. Wyszukiwanie
```javascript
// Wyszukiwanie w plikach
{
  name: 'search_files',
  description: 'Wyszukuje pliki wedÅ‚ug wzorca',
  inputSchema: {
    type: 'object',
    properties: {
      pattern: { type: 'string' },
      directory: { type: 'string' }
    }
  }
}
```

## ğŸš€ PrzykÅ‚adowe projekty

### 1. Chatbot AI
```bash
cd projects/chatbot
npm install
npm start
```

Funkcje:
- Konwersacja z uÅ¼ytkownikiem
- PamiÄ™Ä‡ kontekstu
- Integracja z MCP dla dostÄ™pu do plikÃ³w

### 2. Asystent programisty
```bash
cd projects/code-assistant
python main.py
```

Funkcje:
- Generowanie kodu
- Refaktoryzacja
- Dokumentacja
- Analiza bÅ‚Ä™dÃ³w

### 3. Analizator danych
```bash
cd projects/data-analyzer
python analyze.py --input data.csv
```

Funkcje:
- Analiza statystyczna
- Wizualizacje
- Predykcje ML
- Raporty

## ğŸ’¡ Najlepsze praktyki

### Fine-tuning
1. **Zacznij od maÅ‚ego**: Testuj na maÅ‚ym datasecie
2. **Monitoruj metryki**: Loss, accuracy, overfitting
3. **UÅ¼ywaj LoRA**: Dla efektywnoÅ›ci pamiÄ™ci
4. **Walidacja**: Zawsze miej zbiÃ³r walidacyjny

### MCP
1. **BezpieczeÅ„stwo**: Waliduj wszystkie wejÅ›cia
2. **WydajnoÅ›Ä‡**: Cache'uj wyniki
3. **BÅ‚Ä™dy**: ObsÅ‚uguj gracefully
4. **Dokumentacja**: Opisuj wszystkie narzÄ™dzia

## ğŸ“Š PorÃ³wnanie wydajnoÅ›ci

| Model | Zadanie | GPU | Czas treningu | Accuracy |
|-------|---------|-----|---------------|----------|
| Phi-2 | Instrukcje | RTX 3090 | 2h | 89% |
| LLaMA-7B | Chat | A100 | 8h | 92% |
| BERT | Klasyfikacja | M1 Max | 1h | 94% |

## ğŸ› ï¸ Troubleshooting

### Problem: Out of Memory
```python
# RozwiÄ…zanie 1: Zmniejsz batch size
training_args.per_device_train_batch_size = 1

# RozwiÄ…zanie 2: UÅ¼yj gradient accumulation
training_args.gradient_accumulation_steps = 16

# RozwiÄ…zanie 3: Kwantyzacja
model = load_in_4bit=True
```

### Problem: Wolny trening
```python
# UÅ¼yj mixed precision
training_args.fp16 = True  # lub bf16

# WiÄ™cej workerÃ³w
dataloader_num_workers = 4

# Kompilacja modelu (PyTorch 2.0+)
model = torch.compile(model)
```

## ğŸ“š Dodatkowe zasoby

### Tutoriale
1. [Fine-tuning krok po kroku](../fine-tuning/windows/przewodnik-windows.md)
2. [MCP od podstaw](../wprowadzenie/podstawy-ai-mcp.md)
3. [Optymalizacja dla Mac](../fine-tuning/mac/przewodnik-mac.md)

### Datasety
- [Hugging Face Datasets](https://huggingface.co/datasets)
- [Polish NLP Resources](https://github.com/topics/polish-nlp)
- [Code datasets](https://huggingface.co/datasets?task_categories=task_categories:text-generation&tags=code)

### Modele
- [MaÅ‚e modele (<3B)](https://huggingface.co/models?other=base_model:size_categories:0-3B)
- [Modele dla polskiego](https://huggingface.co/models?language=pl)
- [Modele do kodu](https://huggingface.co/models?pipeline_tag=text-generation&tags=code)

## ğŸ® Interaktywne demo

Uruchom Jupyter Notebook z przykÅ‚adami:
```bash
jupyter notebook interactive_examples.ipynb
```

Zawiera:
- Interaktywny fine-tuning
- Wizualizacja procesu uczenia
- PorÃ³wnanie modeli
- Playground MCP

## ğŸ¤ WspÃ³Å‚praca

Masz ciekawy przykÅ‚ad? PrzeÅ›lij PR!

1. Fork repozytorium
2. Dodaj przykÅ‚ad do odpowiedniego katalogu
3. Zaktualizuj README
4. StwÃ³rz Pull Request

---

SzczÄ™Å›liwego kodowania! ğŸš€